{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from data_loader import CCAgTDataset\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils import dice_loss\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "image_root = Path('./data/images/')\n",
    "mask_root = Path('./data/masks/')\n",
    "\n",
    "model_root = Path('./model/')\n",
    "result_root = Path('./image/')\n",
    "log_root = Path('./log/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations and random setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data configuration\n",
    "SCALE_SIZE = (800, 800)\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "# GPU resources\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(12)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "dataset = CCAgTDataset(image_root, mask_root, scale_size=SCALE_SIZE)\n",
    "\n",
    "# Training, validation and test split\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "train_set, valid_set, test_set = random_split(dataset, [0.7, 0.1, 0.2], generator=generator)\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "valid_loader = DataLoader(valid_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img_and_mask(img, ground, mask, image_name:str):\n",
    "    fig = plt.figure(figsize=(12, 5))\n",
    "    plt.title(image_name)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title('Image')\n",
    "    plt.imshow(img.permute(1, 2, 0))\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title('Ground')\n",
    "    plt.imshow(ground, vmin=0, vmax=7)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title('Pred')\n",
    "    plt.imshow(mask, vmin=0, vmax=7)\n",
    "    plt.savefig(result_root / f'{image_name}.png')\n",
    "    plt.close()\n",
    "\n",
    "cmap = plt.get_cmap('Dark2')\n",
    "\n",
    "def plot_fusion(ax, image, mask, alpha=0.05):\n",
    "    for c, binary in enumerate((mask == c).astype(np.uint8) for c in range(1, 8)):\n",
    "        countours, hierarchy = cv2.findContours(binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        ax.imshow(image, cmap='tab10', alpha=alpha)\n",
    "        color = cmap(c) if alpha < 1 else 'r'\n",
    "        for i in range(len(countours)):\n",
    "            ax.plot(countours[i][:, :, 0], countours[i][:, :, 1], c=color, linewidth=1.5)\n",
    "\n",
    "def plot_inference(imgs, grounds, masks, image_names):\n",
    "    # Create a 5x6 grid of subplots\n",
    "    count = len(imgs)\n",
    "    fig, axs = plt.subplots(6, count, figsize=(20, 4*count))  # Adjust the figsize as per your preference\n",
    "\n",
    "    # Iterate through each subplot and plot something simple\n",
    "    for i in range(count):\n",
    "        img = imgs[i].permute(1, 2, 0).numpy()\n",
    "        ground = grounds[i].numpy()\n",
    "        mask = masks[i].numpy()\n",
    "        name = image_names[i]\n",
    "        axs[0, i].imshow(img)\n",
    "        axs[0, i].set_title(name)\n",
    "        axs[1, i].imshow(ground, cmap='bone', vmin=0, vmax=7)\n",
    "        plot_fusion(axs[2, i], img, ground, alpha=0.05)\n",
    "        axs[3, i].imshow(mask, cmap='bone', vmin=0, vmax=7)\n",
    "        plot_fusion(axs[4, i], img, mask, alpha=0.05)\n",
    "        plot_fusion(axs[5, i], ground, mask, alpha=1)\n",
    "\n",
    "        for j in range(6):\n",
    "            axs[j, i].axis('off')\n",
    "\n",
    "    # Adjust layout and show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(result_root / f'{image_names[0]}.png')\n",
    "    plt.close()\n",
    "\n",
    "def plot_metrics(train_metrics, valid_metrics, metric_name):\n",
    "    plt.title(metric_name)\n",
    "    plt.plot(train_metrics, label=f'train {metric_name}')\n",
    "    plt.plot(valid_metrics, label=f'valid {metric_name}')\n",
    "    plt.legend()\n",
    "    plt.savefig(log_root / f'{metric_name}.png')\n",
    "    plt.close()\n",
    "\n",
    "def resize_mask(mask, size):\n",
    "    mask = mask.unsqueeze(0).float()\n",
    "    mask = F.interpolate(mask, size=size, mode=\"nearest\").squeeze(0)\n",
    "    return mask.long().contiguous()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric: iou, dice, PA, cPA, mPA\n",
    "def calculate_iou(predicted_mask, ground_truth_mask):\n",
    "    intersection = torch.logical_and(predicted_mask, ground_truth_mask).sum().item()\n",
    "    union = torch.logical_or(predicted_mask, ground_truth_mask).sum().item()\n",
    "    iou = intersection / union if union != 0 else 0\n",
    "    return iou\n",
    "\n",
    "def calculate_class_TF(predicted_masks, ground_truth_masks, num_classes, class_TF=[]):\n",
    "    thresholds = torch.arange(0.5, 1.0, 0.05)\n",
    "\n",
    "    if len(class_TF) == 0:\n",
    "        for class_idx in range(num_classes):\n",
    "            class_thred_TF = []\n",
    "            for threshold in thresholds:\n",
    "                class_thred_TF.append({'true_positives': 0, 'false_positives': 0, 'false_negatives': 0})\n",
    "            class_TF.append(class_thred_TF)\n",
    "\n",
    "    for class_idx in range(num_classes):\n",
    "        for tid, threshold in enumerate(thresholds):\n",
    "            for i in range(len(predicted_masks)):\n",
    "                pred_mask = (predicted_masks[i] == class_idx).bool()\n",
    "                gt_mask = (ground_truth_masks[i] == class_idx).bool()\n",
    "\n",
    "                iou = calculate_iou(pred_mask, gt_mask)\n",
    "                if iou >= threshold:\n",
    "                    class_TF[class_idx][tid]['true_positives'] += 1\n",
    "                else:\n",
    "                    class_TF[class_idx][tid]['false_positives'] += 1\n",
    "                    class_TF[class_idx][tid]['false_negatives'] += 1 if iou < 0.5 else 0\n",
    "\n",
    "    return class_TF\n",
    "\n",
    "def calculate_mean_iou(predicted_masks, ground_truth_masks, num_classes):\n",
    "    class_iou = torch.zeros(num_classes)\n",
    "    for class_idx in range(num_classes):\n",
    "        class_mask_pred = (predicted_masks == class_idx)\n",
    "        class_mask_gt = (ground_truth_masks == class_idx)\n",
    "        class_iou[class_idx] = calculate_iou(class_mask_pred, class_mask_gt)\n",
    "\n",
    "    mean_iou = class_iou.sum() / (class_iou != 0).sum()  # Calculate mean ignoring classes with IoU = 0\n",
    "    return mean_iou.item()\n",
    "\n",
    "def calculate_dice(predicted_mask, ground_truth_mask):\n",
    "    intersection = torch.logical_and(predicted_mask, ground_truth_mask).sum().item()\n",
    "    dice = (2. * intersection) / (predicted_mask.sum().item() + ground_truth_mask.sum().item()) if (predicted_mask.sum().item() + ground_truth_mask.sum().item()) != 0 else 0\n",
    "    return dice\n",
    "\n",
    "def calculate_dice_per_class(predicted_masks, ground_truth_masks, num_classes):\n",
    "    dice_scores = []\n",
    "    smooth = 1e-6  # Smoothing factor to avoid division by zero\n",
    "\n",
    "    for class_idx in range(num_classes):\n",
    "        pred = predicted_masks == class_idx\n",
    "        target = ground_truth_masks == class_idx\n",
    "\n",
    "        intersection = (pred & target).sum().item()\n",
    "        union = pred.sum().item() + target.sum().item()\n",
    "\n",
    "        dice = (2. * intersection + smooth) / (union + smooth)\n",
    "        dice_scores.append(dice)\n",
    "\n",
    "    return dice_scores\n",
    "\n",
    "def calculate_mean_dice(dice_scores):\n",
    "    return sum(dice_scores) / len(dice_scores)\n",
    "\n",
    "def calculate_pixel_accuracy(predicted_mask, ground_truth_mask):\n",
    "    correct_pixels = (predicted_mask == ground_truth_mask).sum().item()\n",
    "    total_pixels = ground_truth_mask.numel()\n",
    "    pixel_accuracy = correct_pixels / total_pixels\n",
    "    return pixel_accuracy\n",
    "\n",
    "def calculate_class_pixel_accuracy(predicted_masks, ground_truth_masks, num_classes):\n",
    "    class_pixel_accuracy = torch.zeros(num_classes)\n",
    "    for class_idx in range(num_classes):\n",
    "        class_mask = (ground_truth_masks == class_idx)\n",
    "        correct_pixels = (predicted_masks == ground_truth_masks)[class_mask].sum().item()\n",
    "        total_pixels = class_mask.sum().item()\n",
    "        class_pixel_accuracy[class_idx] = correct_pixels / total_pixels if total_pixels != 0 else 0\n",
    "    return class_pixel_accuracy\n",
    "\n",
    "def calculate_mean_pixel_accuracy(class_pixel_accuracy):\n",
    "    return class_pixel_accuracy.mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        # Encoder path\n",
    "        self.conv_down1 = DoubleConv(in_channels, 64)\n",
    "        self.conv_down2 = DoubleConv(64, 128)\n",
    "        self.conv_down3 = DoubleConv(128, 256)\n",
    "        self.conv_down4 = DoubleConv(256, 512)\n",
    "        self.conv_down5 = DoubleConv(512, 1024)  # Additional layer\n",
    "        \n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # Decoder path\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.conv_up4 = DoubleConv(1024+512, 512)  # Additional layer\n",
    "        self.conv_up3 = DoubleConv(512+256, 256)\n",
    "        self.conv_up2 = DoubleConv(256+128, 128)\n",
    "        self.conv_up1 = DoubleConv(128+64, 64)\n",
    "        \n",
    "        self.final_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder path\n",
    "        conv1 = self.conv_down1(x)\n",
    "        x = self.maxpool(conv1)\n",
    "        \n",
    "        conv2 = self.conv_down2(x)\n",
    "        x = self.maxpool(conv2)\n",
    "        \n",
    "        conv3 = self.conv_down3(x)\n",
    "        x = self.maxpool(conv3)\n",
    "        \n",
    "        conv4 = self.conv_down4(x)\n",
    "        x = self.maxpool(conv4)\n",
    "\n",
    "        # Additional layer in encoder\n",
    "        x = self.conv_down5(x)\n",
    "        \n",
    "        # Decoder path\n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, conv4], dim=1)\n",
    "        x = self.conv_up4(x)\n",
    "        \n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, conv3], dim=1)\n",
    "        x = self.conv_up3(x)\n",
    "        \n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, conv2], dim=1)\n",
    "        x = self.conv_up2(x)\n",
    "        \n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, conv1], dim=1)\n",
    "        x = self.conv_up1(x)\n",
    "        \n",
    "        x = self.final_conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "input_channels = 3\n",
    "output_channels = 8 # number of classes\n",
    "lr = 1e-5\n",
    "num_epochs = 100\n",
    "train_mode = False\n",
    "\n",
    "model = UNet(input_channels, output_channels).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=1e-8, momentum=0.9, foreach=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_miou = 0.0\n",
    "    running_mdice = 0.0\n",
    "    running_pa = 0.0\n",
    "    running_mpa = 0.0\n",
    "    processed_data = 0\n",
    "\n",
    "    i_bar = tqdm(dataloader, desc=\"Training\")\n",
    "    for batch_idx, data in enumerate(i_bar):\n",
    "        inputs = data['rescale_img'].to(device)\n",
    "        labels = data['rescale_mask'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # with torch.autocast(device_type=device):\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        d_loss = dice_loss(F.softmax(outputs, dim=1).float(),\n",
    "                            F.one_hot(labels, num_classes=output_channels).permute(0, 3, 1, 2).float(),\n",
    "                            multiclass=True)\n",
    "        loss += d_loss\n",
    "        pred = torch.argmax(outputs, dim=1)\n",
    "        \n",
    "        # resize the predicted mask to the original size\n",
    "        origin_labels = data['mask'].to(device)\n",
    "        pred = resize_mask(pred, origin_labels.shape[-2:])\n",
    "        \n",
    "        miou = calculate_mean_iou(pred, origin_labels, output_channels)\n",
    "        mdice = calculate_mean_dice(calculate_dice_per_class(pred, origin_labels, output_channels))\n",
    "        pa = calculate_pixel_accuracy(pred, origin_labels)\n",
    "        mpa = calculate_mean_pixel_accuracy(calculate_class_pixel_accuracy(pred, origin_labels, output_channels))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # scheduler.step(d_loss)\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_miou += miou * inputs.size(0)\n",
    "        running_mdice += mdice * inputs.size(0)\n",
    "        running_pa += pa * inputs.size(0)\n",
    "        running_mpa += mpa * inputs.size(0)\n",
    "        processed_data += inputs.size(0)\n",
    "        i_bar.set_postfix_str(f\"Loss: {loss.item():.4f}| mIoU: {miou:.4f}, mDice: {mdice:.4f}, PA: {pa:.4f}, mPA: {mpa:.4f}\")\n",
    "        # plot_img_and_mask(data['image'][0], origin_labels[0].cpu(), pred[0].cpu(), \"Train\")\n",
    "\n",
    "    train_loss = running_loss / processed_data\n",
    "    train_miou = running_miou / processed_data\n",
    "    train_mdice = running_mdice / processed_data\n",
    "    train_pa = running_pa / processed_data\n",
    "    train_mpa = running_mpa / processed_data\n",
    "\n",
    "    return train_loss, train_miou, train_mdice, train_pa, train_mpa\n",
    "\n",
    "def valid_step(model, dataloader, criterion, device, evaluate=False):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_miou = 0.0\n",
    "    running_pa = 0.0\n",
    "    running_mdice = 0.0\n",
    "    running_mpa = 0.0\n",
    "    processed_size = 0\n",
    "\n",
    "    i_bar = tqdm(dataloader, desc=\"Validation\" if not evaluate else \"Testing\")\n",
    "    for batch_idx, data in enumerate(i_bar):\n",
    "        inputs = data['rescale_img'].to(device)\n",
    "        labels = data['rescale_mask'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # with torch.autocast(device_type=device):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            d_loss = dice_loss(F.softmax(outputs, dim=1).float(),\n",
    "                            F.one_hot(labels, num_classes=output_channels).permute(0, 3, 1, 2).float(),\n",
    "                            multiclass=True)\n",
    "            loss += d_loss\n",
    "            pred = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            # resize the predicted mask to the original size\n",
    "            origin_labels = data['mask'].to(device)\n",
    "            pred = resize_mask(pred, origin_labels.shape[-2:])\n",
    "\n",
    "            miou = calculate_mean_iou(pred, origin_labels, output_channels)\n",
    "            mdice = calculate_mean_dice(calculate_dice_per_class(pred, origin_labels, output_channels))\n",
    "            pa = calculate_pixel_accuracy(pred, origin_labels)\n",
    "            mpa = calculate_mean_pixel_accuracy(calculate_class_pixel_accuracy(pred, origin_labels, output_channels))\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        processed_size += inputs.size(0)\n",
    "        running_miou += miou * inputs.size(0)\n",
    "        running_mdice += mdice * inputs.size(0)\n",
    "        running_pa += pa * inputs.size(0)\n",
    "        running_mpa += mpa * inputs.size(0)\n",
    "\n",
    "        i_bar.set_postfix_str(f\"Loss: {loss.item():.4f}| mIoU: {miou:.4f}, mDice: {mdice:.4f}, PA: {pa:.4f}, mPA: {mpa:.4f}\")\n",
    "\n",
    "        # plot_img_and_mask(data['image'][0], origin_labels[0].cpu(), pred[0].cpu(), \"Validation\")\n",
    "        \n",
    "\n",
    "    valid_loss = running_loss / processed_size\n",
    "    valid_miou = running_miou / processed_size\n",
    "    valid_mdice = running_mdice / processed_size\n",
    "    valid_pa = running_pa / processed_size\n",
    "    valid_mpa = running_mpa / processed_size\n",
    "\n",
    "    return valid_loss, valid_miou, valid_mdice, valid_pa, valid_mpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, valid_loader, criterion, optimizer, device, epochs=10):\n",
    "    best_loss = float('inf')\n",
    "\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "\n",
    "    train_mious = []\n",
    "    valid_mious = []\n",
    "    train_mdices = []\n",
    "    valid_mdices = []\n",
    "    train_pas = []\n",
    "    valid_pas = []\n",
    "    train_mpas = []\n",
    "    valid_mpas = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1} of {epochs}\")\n",
    "        train_loss, train_miou, train_mdice, train_pa, train_mpa = train_step(model, train_loader, criterion, optimizer, device)\n",
    "        valid_loss, valid_miou, valid_mdice, valid_pa, valid_mpa = valid_step(model, valid_loader, criterion, device)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "        train_mious.append(train_miou)\n",
    "        valid_mious.append(valid_miou)\n",
    "        train_mdices.append(train_mdice)\n",
    "        valid_mdices.append(valid_mdice)\n",
    "        train_pas.append(train_pa)\n",
    "        valid_pas.append(valid_pa)\n",
    "        train_mpas.append(train_mpa)\n",
    "        valid_mpas.append(valid_mpa)\n",
    "\n",
    "        print(f\"Train Loss: {train_loss:.4f} | Train mIoU: {train_miou:.4f} | Train mDice: {train_mdice:.4f} | Train PA: {train_pa:.4f}, Train mPA: {train_mpa:.4f}\")\n",
    "        print(f\"Valid Loss: {valid_loss:.4f} | Valid mIoU: {valid_miou:.4f} | Valid mDice: {valid_mdice:.4f} | Valid PA: {valid_pa:.4f}, Valid mPA: {valid_mpa:.4f}\")\n",
    "\n",
    "        # visualize the metrics\n",
    "        plot_metrics(train_losses, valid_losses, 'Loss')\n",
    "        plot_metrics(train_mious, valid_mious, 'mIoU')\n",
    "        plot_metrics(train_mdices, valid_mdices, 'mDice')\n",
    "        plot_metrics(train_pas, valid_pas, 'PA')\n",
    "        plot_metrics(train_mpas, valid_mpas, 'mPA')\n",
    "\n",
    "        if valid_loss < best_loss:\n",
    "            best_loss = valid_loss\n",
    "            torch.save(model.state_dict(), model_root / 'best_model.pth')\n",
    "\n",
    "def evaluate(model, test_loader, criterion, device):\n",
    "    test_loss, test_miou, test_mdice, test_pa, test_mpa = valid_step(model, test_loader, criterion, device, evaluate=True)\n",
    "    print(f\"Test Loss: {test_loss:.4f} | Test mIoU: {test_miou:.4f} | Test mDice: {test_mdice:.4f} | Test PA: {test_pa:.4f} | Test mPA: {test_mpa:.4f}\")\n",
    "\n",
    "def inference(model, test_loader, device):\n",
    "    buffer = {'image': [], 'ground': [], 'pred': [], 'name': []}\n",
    "    buffer_count = 0\n",
    "\n",
    "    class_TF = []\n",
    "    \n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(tqdm(test_loader, desc=\"Inference\")):\n",
    "            inputs = data['rescale_img'].to(device)\n",
    "            labels = data['rescale_mask'].to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            pred = torch.argmax(outputs, dim=1)\n",
    "            origin_labels = data['mask'].to(device)\n",
    "            pred = resize_mask(pred, origin_labels.shape[-2:])\n",
    "\n",
    "            class_TF = calculate_class_TF(pred, origin_labels, output_channels, class_TF)\n",
    "\n",
    "            if buffer_count > 50:\n",
    "                print(\"Collecting enough data for inference\")\n",
    "                break\n",
    "\n",
    "            # Plot that complex table\n",
    "            for i in range(BATCH_SIZE):\n",
    "                buffer['image'].append(data['image'][i])\n",
    "                buffer['ground'].append(origin_labels[i].cpu())\n",
    "                buffer['pred'].append(pred[i].cpu())\n",
    "                buffer['name'].append(f\"test/{data['name'][i]}\")\n",
    "\n",
    "                buffer_count += 1\n",
    "                # plot_img_and_mask(data['image'][i], origin_labels[i].cpu(), pred[i].cpu(), f\"test/{data['name'][i]}\")\n",
    "                if buffer_count % 5 == 0:\n",
    "                    plot_inference(buffer['image'], buffer['ground'], buffer['pred'], buffer['name'])\n",
    "                    buffer = {'image': [], 'ground': [], 'pred': [], 'name': []}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size:  9339\n",
      "Image size:  torch.Size([800, 800])\n",
      "Train set size:  6538\n",
      "Valid set size:  934\n",
      "Test set size:  1867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 467/467 [36:40<00:00,  4.71s/it, Loss: 0.4511| mIoU: 0.8034, mDice: 0.9291, PA: 0.9993, mPA: 0.5855]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.5784 | Test mIoU: 0.6733 | Test mDice: 0.5811 | Test PA: 0.9967 | Test mPA: 0.4952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference:   3%|▎         | 13/467 [06:57<4:10:51, 33.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting enough data for inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference:   3%|▎         | 13/467 [07:03<4:06:22, 32.56s/it]\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset size: \", len(dataset))\n",
    "print(\"Image size: \", dataset[0]['rescale_mask'].shape)\n",
    "print(\"Train set size: \", len(train_set))\n",
    "print(\"Valid set size: \", len(valid_set))\n",
    "print(\"Test set size: \", len(test_set))\n",
    "\n",
    "if train_mode:\n",
    "    train(model, train_loader, valid_loader, criterion, optimizer, device, epochs=num_epochs)\n",
    "\n",
    "# load the best model\n",
    "model.load_state_dict(torch.load(model_root / 'best_model.pth'))\n",
    "evaluate(model, test_loader, criterion, device)\n",
    "inference(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
